{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4f74189-8733-4f3b-8ee9-7ee0c40d3697",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/08/28 11:08:52 WARN Utils: Your hostname, EmmanuelPC resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "25/08/28 11:08:52 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/08/28 11:08:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+-----------------+-----------+----+\n",
      "|  id|name_primary|            email|name_backup| age|\n",
      "+----+------------+-----------------+-----------+----+\n",
      "|A123|        NULL|alice@example.com|       NULL|  34|\n",
      "|B456|         Bob|             NULL|       NULL|NULL|\n",
      "|C789|        NULL|             NULL|       NULL|  27|\n",
      "|D000|        NULL|             NULL|        Alt|NULL|\n",
      "+----+------------+-----------------+-----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"JupyterPySpark\")\n",
    "    .master(\"local[1]\")\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"false\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "df = spark.createDataFrame(\n",
    "    [\n",
    "        (\"A123\", None, \"alice@example.com\", None, 34),\n",
    "        (\"B456\", \"Bob\", None, None, None),\n",
    "        (\"C789\", None, None, None, 27),\n",
    "        (\"D000\", None, None, \"Alt\", None),\n",
    "    ],\n",
    "    [\"id\", \"name_primary\", \"email\", \"name_backup\", \"age\"]\n",
    ")\n",
    "\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5de3708-74e0-420f-ba05-351745d82088",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import coalesce, col, lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3eca0e8-3776-43be-a9da-0d49306623e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+\n",
      "|coalesce(name_primary, toto)|\n",
      "+----------------------------+\n",
      "|                        toto|\n",
      "|                         Bob|\n",
      "|                        toto|\n",
      "|                        toto|\n",
      "+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(coalesce(col('name_primary'),lit('toto') )).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16e410f6-8930-497e-b1cc-4b79ca32e07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|secondary|\n",
      "+---------+\n",
      "|       34|\n",
      "|      Bob|\n",
      "|       27|\n",
      "|     toto|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(coalesce(col('name_primary'),col('age'),lit('toto') ).alias('secondary')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a348ec4-3a08-4681-bf3a-8739380959d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+-----------------+-----------+----+\n",
      "|  id|name_primary|            email|name_backup| age|\n",
      "+----+------------+-----------------+-----------+----+\n",
      "|A123|        NULL|alice@example.com|       NULL|  34|\n",
      "|B456|         Bob|             NULL|       NULL|NULL|\n",
      "|C789|        NULL|             NULL|       NULL|  27|\n",
      "|D000|        NULL|             NULL|        Alt|NULL|\n",
      "+----+------------+-----------------+-----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8ab8271-8153-45c0-9177-4aca07360f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+-----------------+-----------+----+\n",
      "|  id|name_primary|            email|name_backup| age|\n",
      "+----+------------+-----------------+-----------+----+\n",
      "|A123|     Unknown|alice@example.com|       Emma|  34|\n",
      "|B456|         Bob|             NULL|       Emma|NULL|\n",
      "|C789|     Unknown|             NULL|       Emma|  27|\n",
      "|D000|     Unknown|             NULL|        Alt|NULL|\n",
      "+----+------------+-----------------+-----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.fillna({'name_primary':'Unknown' , 'name_backup':'Emma'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4f3c665-7ab7-41f2-a0d7-b713e93b8ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+-----------------+-----------+----+\n",
      "|  id|name_primary|            email|name_backup| age|\n",
      "+----+------------+-----------------+-----------+----+\n",
      "|A123|        NULL|alice@example.com|       NULL|  34|\n",
      "|C789|        NULL|             NULL|       NULL|  27|\n",
      "|D000|        NULL|             NULL|        Alt|NULL|\n",
      "+----+------------+-----------------+-----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter( col('name_primary').isNull() ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "307c1c60-a77f-4777-87e1-a1b9a6054763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter( col('name_primary').isNull() ).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e80bc5ba-ee74-4482-87c2-e3eb3a8ff796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter( col('name_primary').isNotNull() ).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c4a7900-1736-4f11-888f-380e5e00c9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+-----+-----------+----+\n",
      "|  id|name_primary|email|name_backup| age|\n",
      "+----+------------+-----+-----------+----+\n",
      "|B456|         Bob| NULL|       NULL|NULL|\n",
      "+----+------------+-----+-----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter( col('name_primary').isNotNull() ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ba6fb1-567a-4d22-bec5-93abda7c33a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
